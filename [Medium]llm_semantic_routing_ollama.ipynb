{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMr38PllIDr+TFRutOijp96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sopralapanca/CHL-clinical-data-encoder/blob/master/%5BMedium%5Dllm_semantic_routing_ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "una delle sfide più impegnative al momento è quella di avere un modello che fa semantic routing -> usiamo un llm\n",
        "\n",
        "nella prima parte vediamo come strutturare il progetto con un semplce LLM\n",
        "nella seconda parte utilizzeremo un rag\n",
        "\n",
        "disclaimer i risultati potrebbero essere diversi in quanto il modello puo dare altre cose in ouput. cercare di essere più precisi possibili nei prompt"
      ],
      "metadata": {
        "id": "WD7YEUkYq_mN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disclaimer"
      ],
      "metadata": {
        "id": "hsc3jUUY3KSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write disclaimer"
      ],
      "metadata": {
        "id": "nYzIyJ1R3NM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "h8hfOlu83VQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading Ollama"
      ],
      "metadata": {
        "id": "38joaOP63k6i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO57NF7Iq41N",
        "outputId": "ab1e62fc-e3ad-4a58-93ac-219fa200293f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13269    0 13269    0     0  47878      0 --:--:-- --:--:-- --:--:-- 47902\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama serve > server.log 2>&1 & # ollama will run by default at 127.0.0.1:11434"
      ],
      "metadata": {
        "id": "EA6ojgFjKCjX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "agents_model = \"qwen2.5:1.5b\"\n",
        "!ollama pull {agents_model}"
      ],
      "metadata": {
        "id": "9Fja-fxErWaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "router_model = \"qwen2.5:3b\"\n",
        "!ollama pull {router_model}"
      ],
      "metadata": {
        "id": "vlvvAtoqZu0A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNI4wMXGsHxM",
        "outputId": "722d01e9-c541-4315-86f0-1b16c26f66ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME            ID              SIZE      MODIFIED               \n",
            "qwen2.5:3b      357c53fb659c    1.9 GB    Less than a second ago    \n",
            "qwen2.5:1.5b    65ec06548149    986 MB    20 seconds ago            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serving the models at different ports"
      ],
      "metadata": {
        "id": "Ad-LVCz24Zgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "9XbekT2G4XjW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OLLAMA_HOST'] = \"127.0.0.1:11438\"\n",
        "!ollama serve > server.log 2>&1 &"
      ],
      "metadata": {
        "id": "MRHt3_5YJ3ne"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OLLAMA_HOST'] = \"127.0.0.1:11439\"\n",
        "!ollama serve > server.log 2>&1 &"
      ],
      "metadata": {
        "id": "8G9qLDVl4fVu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages"
      ],
      "metadata": {
        "id": "cyMjXtzc4joF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openai==1.57.4 ollama==0.4.4 pydantic==2.10.3"
      ],
      "metadata": {
        "id": "JTVmOWKfK50t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools definition"
      ],
      "metadata": {
        "id": "DqJHjWYQ4IXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "\n",
        "summarizer_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"get_summarization\",\n",
        "        \"description\": \"Call this method whenever you need to perform a summarization task, for example when a user asks 'Summarize this paragraph'. This method does not accepts input parameters.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {},\n",
        "            \"required\": [],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "topics_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"get_topics\",\n",
        "      \"description\": \"Call this whenever you need to perform a topic extraction extraction task, for example when a user asks 'What are the topics of this paragraph?'. This method does not accepts input parameters.\",\n",
        "      \"parameters\": {\n",
        "          \"type\": \"object\",\n",
        "          \"properties\": {},\n",
        "          \"required\": [],\n",
        "          \"additionalProperties\": False\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "today_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"get_current_day\",\n",
        "      \"description\": \"Get the current day of the week. Call this whenever you need to know what day it is today, for example when the user asks 'What day is it?'. This method does not accepts input parameters.\",\n",
        "      \"parameters\": {\n",
        "          \"type\": \"object\",\n",
        "          \"properties\": {},\n",
        "          \"required\": [],\n",
        "          \"additionalProperties\": False\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "tools = [topics_tool, summarizer_tool, today_tool]\n",
        "\n"
      ],
      "metadata": {
        "id": "DTnjvhZU6Irg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "yvhgQ2ow5MDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "summarizer_client = OpenAI(\n",
        "    base_url = 'http://localhost:11439/v1',\n",
        "    api_key='ollama', # required, but unused\n",
        ")\n",
        "\n",
        "general_client = OpenAI(\n",
        "    base_url = 'http://localhost:11438/v1',\n",
        "    api_key='ollama', # required, but unused\n",
        ")"
      ],
      "metadata": {
        "id": "FbVKu5mHK68v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_history_agents(messages: list[dict[str, str]], sys_prompt: str):\n",
        "    history = [{\"role\":\"system\", \"content\": sys_prompt}]\n",
        "\n",
        "    for message in messages:\n",
        "      if message[\"role\"] != \"system\":\n",
        "        history.append(message)\n",
        "\n",
        "    return history\n",
        "\n",
        "def get_summarization(history: list[dict[str, str]]):\n",
        "  print(\"calling summarization model\")\n",
        "\n",
        "  sys_prompt = \"You are a summarizer agent. Your only role is to summarize user message. When user asks for other action or want to chit-chat just answer 'Pass.'\"\n",
        "\n",
        "  response = summarizer_client.chat.completions.create(\n",
        "    model=agents_model,\n",
        "    messages=build_history_agents(history, sys_prompt),\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content\n",
        "\n",
        "def get_topics(history: list[dict[str, str]]):\n",
        "  print(\"calling topic model\")\n",
        "  sys_prompt = \"You are a topic extractor model. Your role is to examinie user message and extract the topics. When user asks for other action or want to chit-chat just answer 'Pass.'\"\n",
        "\n",
        "  response = general_client.chat.completions.create(\n",
        "    model=agents_model,\n",
        "    messages=build_history_agents(history, sys_prompt),\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content\n",
        "\n",
        "import datetime\n",
        "def get_current_day():\n",
        "  print(\"calling today model\")\n",
        "\n",
        "  return datetime.datetime.now().strftime(\"%A\")\n"
      ],
      "metadata": {
        "id": "Xc-GClLXHdfl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "hw6Dlkfu6n5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def execute_function_call(response, history):\n",
        "  if response.choices[0].finish_reason == \"tool_calls\":\n",
        "    tool_call = response.choices[0].message.tool_calls[0]\n",
        "    function_name = tool_call.function.name\n",
        "\n",
        "    if function_name == \"get_current_day\":\n",
        "      result = globals()[function_name]()\n",
        "    else:\n",
        "      result = globals()[function_name](history)\n",
        "\n",
        "\n",
        "    function_call_result_message = {\n",
        "      \"role\": \"tool\",\n",
        "      \"content\": json.dumps({\n",
        "          \"result\": result\n",
        "      }),\n",
        "      \"tool_call_id\": response.choices[0].message.tool_calls[0].id\n",
        "    }\n",
        "\n",
        "    response_dict = response.model_dump()\n",
        "    response_dict[\"choices\"][0][\"message\"]\n",
        "\n",
        "    history = history + [response_dict[\"choices\"][0][\"message\"]] + [function_call_result_message]\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "eWu7V70xI-xE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_router_history(messages: list[dict[str, str]], response):\n",
        "    res = response.choices[0].message.content\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": res\n",
        "        }\n",
        "    )\n",
        "    print(res)\n",
        "    return messages"
      ],
      "metadata": {
        "id": "Qb4l782G67ax"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Router"
      ],
      "metadata": {
        "id": "ggSIZmkV5WDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "router_client = OpenAI(\n",
        "    base_url = 'http://localhost:11434/v1',\n",
        "    api_key='ollama', # required, but unused\n",
        ")\n",
        "\n",
        "\n",
        "def call_router(messages: list[dict[str, str]], use_tools=True):\n",
        "\n",
        "  response = router_client.chat.completions.create(\n",
        "    model=router_model,\n",
        "    messages=messages,\n",
        "    tools=tools if use_tools else None\n",
        "  )\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "TmFdTJxxdb0t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with the assistant"
      ],
      "metadata": {
        "id": "1dSLnj__6sJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt = \"You are a routing model. Your role is to understand the chat history and user intent and eventualy to redirect the messages to the correct model that will handle the conversation. Your are allowed to chat with the user but only for chit-chatting, otherwise if you are asked to perform specific tasks just call other functions.\"\n",
        "\n",
        "messages = [\n",
        "  {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": sys_prompt\n",
        "  },\n",
        "  {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Hi, can you summarize this paragraph? The red glow of tail lights indicating another long drive home from work after an even longer 24-hour shift at the hospital. The shift hadn’t been horrible but the constant stream of patients entering the ER meant there was no downtime. She had some of the “regulars” in tonight with new ailments they were sure were going to kill them. It’s amazing what a couple of Tylenol and a physical exam from the doctor did to eliminate their pain, nausea, headache, or whatever other mild symptoms they had. Sometimes she wondered if all they really needed was some interaction with others and a bit of the individual attention they received from the nurses.\"\n",
        "  }\n",
        "]\n",
        "\n",
        "response = call_router(messages)\n",
        "response"
      ],
      "metadata": {
        "id": "_KTzXt-1LDLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c4f5f6-de25-4905-c1bf-2d10a387e1be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-4', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_96uqu57o', function=Function(arguments='{\"text\":\"The red glow of tail lights indicating another long drive home from work after an even longer 24-hour shift at the hospital. The shift hadn’t been horrible but the constant stream of patients entering the ER meant there was no downtime. She had some of the \\'regulars\\' in tonight with new ailments they were sure were going to kill them. It\\'s amazing what a couple of Tylenol and a physical exam from the doctor did to eliminate their pain, nausea, headache, or whatever other mild symptoms they had. Sometimes she wondered if all they really needed was some interaction with others and a bit of the individual attention they received from the nurses.\"}', name='get_summarization'), type='function', index=0)]))], created=1735233239, model='qwen2.5:3b', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=152, prompt_tokens=502, total_tokens=654, completion_tokens_details=None, prompt_tokens_details=None))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = execute_function_call(response, messages)\n",
        "\n",
        "response = call_router(messages, use_tools=False)\n",
        "\n",
        "messagges = build_router_history(messages, response)\n"
      ],
      "metadata": {
        "id": "sul6bDMCLe8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15f52bf-a913-4b00-9710-61686cc80db7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calling summarization model\n",
            "The summary of the paragraph is:\n",
            "\n",
            "A person reflects on their 24-hour shift at the hospital, noting that while it hasn't been terrible overall—constantly dealing with patient influxes without downtime—they often have repeat patients who come back after various minor issues (such as pain and nausea). These issues are typically resolved through medication (Tylenol) along with physical examinations from doctors. The person reflects on how the shifts remind them of how simple interactions and more personalized care can resolve many minor problems associated with being alone in the Emergency Room all day long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Now I want to know what day is it\"\n",
        "  }\n",
        ")\n",
        "\n",
        "response = call_router(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwuWBIv3nVuG",
        "outputId": "624b8ed0-a0ed-4707-b8df-69081c3ae78f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-650', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ppy9ohoc', function=Function(arguments='{}', name='get_current_day'), type='function', index=0)]))], created=1735233249, model='qwen2.5:3b', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=17, prompt_tokens=757, total_tokens=774, completion_tokens_details=None, prompt_tokens_details=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = execute_function_call(response, messages)\n",
        "\n",
        "response = call_router(messages, use_tools=False)\n",
        "messagges = build_router_history(messages, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq_uM5rCqi1i",
        "outputId": "d48540a3-e77b-4567-a302-2a695bf0b945"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calling today model\n",
            "Today is Thursday.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Now can you extract topics from the paragraph that I sent you on the first message?\"\n",
        "  }\n",
        ")\n",
        "\n",
        "response = call_router(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v2p2ly0rs7r",
        "outputId": "0c4df7d4-6847-42ad-f4d1-548848c57acb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-407', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_mzpgu1fu', function=Function(arguments='{}', name='get_topics'), type='function', index=0)]))], created=1735233251, model='qwen2.5:3b', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=16, prompt_tokens=812, total_tokens=828, completion_tokens_details=None, prompt_tokens_details=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = execute_function_call(response, messages)\n",
        "\n",
        "response = call_router(messages, use_tools=False)\n",
        "messagges = build_router_history(messages, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFKxGP2hr5C6",
        "outputId": "11b671ac-c775-441e-fc55-eacbbef1b397"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calling topic model\n",
            "The main topics from the paragraph are:\n",
            "\n",
            "1. A 24-hour shift at the hospital's Emergency Room (ER)\n",
            "2. The constant influx of patients during the shift\n",
            "3. The treatments provided (Tylenol, physical exams)\n",
            "4. Repeat patients with various minor issues\n",
            "5. Reflection on personal care and interactions needed for better patient outcomes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Thank you!! You are a very helpful assistant. Now, say hello to our Medium friends :)\"\n",
        "  }\n",
        ")\n",
        "\n",
        "response = call_router(messages)\n",
        "messagges = build_router_history(messages, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_iMrlbotlwZ",
        "outputId": "12051fa1-dcd1-44f9-de34-a4232d04c464"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello to our Medium friends! How can I assist you further?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the history"
      ],
      "metadata": {
        "id": "CiKNLaTB96IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpkWQTVi7wzf",
        "outputId": "c6f5fb5b-2d46-447a-b28d-d92f3843c0cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are a routing model. Your role is to understand the chat history and user intent and eventualy to redirect the messages to the correct model that will handle the conversation. Your are allowed to chat with the user but only for chit-chatting, otherwise if you are asked to perform specific tasks just call other functions.'},\n",
              " {'role': 'user',\n",
              "  'content': 'Hi, can you summarize this paragraph? The red glow of tail lights indicating another long drive home from work after an even longer 24-hour shift at the hospital. The shift hadn’t been horrible but the constant stream of patients entering the ER meant there was no downtime. She had some of the “regulars” in tonight with new ailments they were sure were going to kill them. It’s amazing what a couple of Tylenol and a physical exam from the doctor did to eliminate their pain, nausea, headache, or whatever other mild symptoms they had. Sometimes she wondered if all they really needed was some interaction with others and a bit of the individual attention they received from the nurses.'},\n",
              " {'content': '',\n",
              "  'refusal': None,\n",
              "  'role': 'assistant',\n",
              "  'audio': None,\n",
              "  'function_call': None,\n",
              "  'tool_calls': [{'id': 'call_96uqu57o',\n",
              "    'function': {'arguments': '{\"text\":\"The red glow of tail lights indicating another long drive home from work after an even longer 24-hour shift at the hospital. The shift hadn’t been horrible but the constant stream of patients entering the ER meant there was no downtime. She had some of the \\'regulars\\' in tonight with new ailments they were sure were going to kill them. It\\'s amazing what a couple of Tylenol and a physical exam from the doctor did to eliminate their pain, nausea, headache, or whatever other mild symptoms they had. Sometimes she wondered if all they really needed was some interaction with others and a bit of the individual attention they received from the nurses.\"}',\n",
              "     'name': 'get_summarization'},\n",
              "    'type': 'function',\n",
              "    'index': 0}]},\n",
              " {'role': 'tool',\n",
              "  'content': '{\"result\": \"Certainly! Here\\'s a summarized version: A person reflects on her 24-hour shift at the hospital, noting that while it hasn\\\\u2019t been terrible, constant patient influxes meant no downtime for her. She often deals with repeat patients who come back after various minor issues that seem severe but are treated with Tylenol and physical examinations resolving by themselves. The shifts remind her how simple interactions and more personal care can alleviate many minor problems associated with long hours alone in the ER.\"}',\n",
              "  'tool_call_id': 'call_96uqu57o'},\n",
              " {'role': 'assistant',\n",
              "  'content': \"The summary of the paragraph is:\\n\\nA person reflects on their 24-hour shift at the hospital, noting that while it hasn't been terrible overall—constantly dealing with patient influxes without downtime—they often have repeat patients who come back after various minor issues (such as pain and nausea). These issues are typically resolved through medication (Tylenol) along with physical examinations from doctors. The person reflects on how the shifts remind them of how simple interactions and more personalized care can resolve many minor problems associated with being alone in the Emergency Room all day long.\"},\n",
              " {'role': 'user', 'content': 'Now I want to know what day is it'},\n",
              " {'content': '',\n",
              "  'refusal': None,\n",
              "  'role': 'assistant',\n",
              "  'audio': None,\n",
              "  'function_call': None,\n",
              "  'tool_calls': [{'id': 'call_ppy9ohoc',\n",
              "    'function': {'arguments': '{}', 'name': 'get_current_day'},\n",
              "    'type': 'function',\n",
              "    'index': 0}]},\n",
              " {'role': 'tool',\n",
              "  'content': '{\"result\": \"Thursday\"}',\n",
              "  'tool_call_id': 'call_ppy9ohoc'},\n",
              " {'role': 'assistant', 'content': 'Today is Thursday.'},\n",
              " {'role': 'user',\n",
              "  'content': 'Now can you extract topics from the paragraph that I sent you on the first message?'},\n",
              " {'content': '',\n",
              "  'refusal': None,\n",
              "  'role': 'assistant',\n",
              "  'audio': None,\n",
              "  'function_call': None,\n",
              "  'tool_calls': [{'id': 'call_mzpgu1fu',\n",
              "    'function': {'arguments': '{}', 'name': 'get_topics'},\n",
              "    'type': 'function',\n",
              "    'index': 0}]},\n",
              " {'role': 'tool',\n",
              "  'content': '{\"result\": \"Sure! The topic extracted from your sentence snippet revolves around a 24-hour shift at an emergency room, describing the work environment and some patient interactions within this setting.\"}',\n",
              "  'tool_call_id': 'call_mzpgu1fu'},\n",
              " {'role': 'assistant',\n",
              "  'content': \"The main topics from the paragraph are:\\n\\n1. A 24-hour shift at the hospital's Emergency Room (ER)\\n2. The constant influx of patients during the shift\\n3. The treatments provided (Tylenol, physical exams)\\n4. Repeat patients with various minor issues\\n5. Reflection on personal care and interactions needed for better patient outcomes\"},\n",
              " {'role': 'user',\n",
              "  'content': 'Thank you!! You are a very helpful assistant. Now, say hello to our Medium friends :)'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hello to our Medium friends! How can I assist you further?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}